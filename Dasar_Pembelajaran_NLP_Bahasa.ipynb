{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEONpk+Yu9/WdLg0xFaaCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fendpray18/NLP_Bahasa/blob/master/Dasar_Pembelajaran_NLP_Bahasa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7p55mSXiIBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "adf029b3-4216-4a02-f387-b7c55f15e08f"
      },
      "source": [
        "pip install Sastrawi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2iuS1lDi8AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3608d89-21ac-4bb9-835e-af32b30d3fc8"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "sentences = \"\\tJumlah pengganguran di Indonesia selama masa pandemi 2020 semakin meningkat 300 %. Hal ini memicu kesenjangan sosial bagi penduduk Indonesia.\"\n",
        "\n",
        "output = stemmer.stem(sentences)\n",
        "\n",
        "print(output)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jumlah pengganguran di indonesia lama masa pandemi 2020 makin tingkat 300 hal ini picu senjang sosial bagi duduk indonesia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXPePhrunN73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e9fbc4e3-920e-4ecd-b8f0-48ce2a78374e"
      },
      "source": [
        "#Case Folding\n",
        "lower_sentences = sentences.lower()\n",
        "\n",
        "print('Kalimat huruf kecil : \"{}\"'.format(lower_sentences))\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "#removing number\n",
        "remove_number = re.sub(r\"\\d+\", \"\", lower_sentences) \n",
        "print('Kalimat remove number : \"{}\"'.format(remove_number))\n",
        "\n",
        "#removing mark text\n",
        "remove_mark = lower_sentences.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "print('Kalimat remove mark text : \"{}\"'.format(remove_mark))\n",
        "\n",
        "#removing whitespace leading & trailing (menghapus tab)\n",
        "remove_whitespace_tab = lower_sentences.strip()\n",
        "print('Kalimat remove whitespace tab : \"{}\"'.format(remove_whitespace_tab))\n",
        "\n",
        "#removing whitespace\n",
        "remove_whitespace_single = re.sub('\\s+', ' ', remove_whitespace_tab)\n",
        "print('Kalimat remove whitespace : \"{}\"'.format(remove_whitespace_single))\n",
        "\n",
        "#Implement each function on case folding\n",
        "remove_mark_final = remove_number.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
        "remove_whitespace_tab_final = remove_mark_final.strip()\n",
        "remove_whitespace_final = re.sub('\\s+', ' ', remove_whitespace_tab_final)\n",
        "print(40*\"=\")\n",
        "print('Kalimat Case Folding : \"{}\"'.format(remove_whitespace_final))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kalimat huruf kecil : \"\tjumlah pengganguran di indonesia selama masa pandemi 2020 semakin meningkat 300 %. hal ini memicu kesenjangan sosial bagi penduduk indonesia.\"\n",
            "Kalimat remove number : \"\tjumlah pengganguran di indonesia selama masa pandemi  semakin meningkat  %. hal ini memicu kesenjangan sosial bagi penduduk indonesia.\"\n",
            "Kalimat remove mark text : \"\tjumlah pengganguran di indonesia selama masa pandemi 2020 semakin meningkat 300  hal ini memicu kesenjangan sosial bagi penduduk indonesia\"\n",
            "Kalimat remove whitespace tab : \"jumlah pengganguran di indonesia selama masa pandemi 2020 semakin meningkat 300 %. hal ini memicu kesenjangan sosial bagi penduduk indonesia.\"\n",
            "Kalimat remove whitespace : \"jumlah pengganguran di indonesia selama masa pandemi 2020 semakin meningkat 300 %. hal ini memicu kesenjangan sosial bagi penduduk indonesia.\"\n",
            "========================================\n",
            "Kalimat Case Folding : \"jumlah pengganguran di indonesia selama masa pandemi semakin meningkat hal ini memicu kesenjangan sosial bagi penduduk indonesia\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1dL3YY-zChe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8a43911c-31c3-404d-ee57-fc8086a44c83"
      },
      "source": [
        "#Tokenizing\n",
        "\n",
        "#Using .split() for spliting each word but if there have more word same, then will be called again\n",
        "spliting = lower_sentences.split()\n",
        "print(\"Kalimat dibagi menjadi kata : {}\".format(spliting))\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "word_token = nltk.tokenize.word_tokenize(remove_whitespace_final)\n",
        "sent_token = nltk.tokenize.sent_tokenize(remove_whitespace_final)\n",
        "\n",
        "print(\"Hasil Kalimat Tokenize Word : \", word_token)\n",
        "print(\"Hasil Kalimat Tokenize Sentence : \", sent_token)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kalimat dibagi menjadi kata : ['jumlah', 'pengganguran', 'di', 'indonesia', 'selama', 'masa', 'pandemi', '2020', 'semakin', 'meningkat', '300', '%.', 'hal', 'ini', 'memicu', 'kesenjangan', 'sosial', 'bagi', 'penduduk', 'indonesia.']\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Hasil Kalimat Tokenize Word :  ['jumlah', 'pengganguran', 'di', 'indonesia', 'selama', 'masa', 'pandemi', 'semakin', 'meningkat', 'hal', 'ini', 'memicu', 'kesenjangan', 'sosial', 'bagi', 'penduduk', 'indonesia']\n",
            "Hasil Kalimat Tokenize Sentence :  ['jumlah pengganguran di indonesia selama masa pandemi semakin meningkat hal ini memicu kesenjangan sosial bagi penduduk indonesia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LreFX2IDOr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d42cf841-eac0-4af0-d12d-61d452e08d70"
      },
      "source": [
        "#Filtering (Stopwords)\n",
        "#Many word have often appear on sentences, then cannot be included on list\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "removed = []\n",
        "\n",
        "liststopword = set(stopwords.words('indonesian'))\n",
        "\n",
        "for t in word_token:\n",
        "  if t not in liststopword:\n",
        "    removed.append(t)\n",
        "\n",
        "print(removed)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['pengganguran', 'indonesia', 'pandemi', 'meningkat', 'memicu', 'kesenjangan', 'sosial', 'penduduk', 'indonesia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-w_51CEYBXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "731c7401-8305-49d0-bd88-c1b67c673c14"
      },
      "source": [
        "#Stopword on Sastrawi Library\n",
        "\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "factor = StopWordRemoverFactory()\n",
        "stopwordss = factor.create_stop_word_remover()\n",
        "\n",
        "stop = stopwordss.remove(remove_whitespace_final)\n",
        "tokens = nltk.tokenize.word_tokenize(stop)\n",
        "\n",
        "print(\"Tokenizing kata :\", word_token)\n",
        "print(\"Tokenizing kata telah stopword :\", tokens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing kata : ['jumlah', 'pengganguran', 'di', 'indonesia', 'selama', 'masa', 'pandemi', 'semakin', 'meningkat', 'hal', 'ini', 'memicu', 'kesenjangan', 'sosial', 'bagi', 'penduduk', 'indonesia']\n",
            "Tokenizing kata telah stopword : ['jumlah', 'pengganguran', 'indonesia', 'selama', 'masa', 'pandemi', 'semakin', 'meningkat', 'ini', 'memicu', 'kesenjangan', 'sosial', 'penduduk', 'indonesia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84c1UhDjdIHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "560843d8-a69e-462c-8d7d-da6d7720aca8"
      },
      "source": [
        "#Adding a few word which have mean stopword\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import ArrayDictionary, StopWordRemover, StopWordRemoverFactory\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_factory = StopWordRemoverFactory().get_stop_words() #load default stopwords\n",
        "more_stopword = ['ini'] #add word which have mean stopword\n",
        "\n",
        "data = (stop_factory + more_stopword) #merge each two data's \n",
        "\n",
        "dictionary = ArrayDictionary(data)\n",
        "str = StopWordRemover(dictionary)\n",
        "token_add = nltk.tokenize.word_tokenize(str.remove(remove_whitespace_final))\n",
        "\n",
        "print(token_add)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['jumlah', 'pengganguran', 'indonesia', 'selama', 'masa', 'pandemi', 'semakin', 'meningkat', 'ini', 'memicu', 'kesenjangan', 'sosial', 'penduduk', 'indonesia']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}